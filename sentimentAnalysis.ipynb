{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "import pydot\n",
    "from keras.layers import Dense, Flatten, Convolution2D, Dropout, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8107, 34, 300)\n"
     ]
    }
   ],
   "source": [
    "# load all the preprocessed movie reviews \n",
    "d_pos = np.load('movie_review/positive.npy')\n",
    "d_neg = np.load('movie_review/negative.npy')\n",
    "\n",
    "data = np.concatenate((d_pos, d_neg))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8107, 2)\n"
     ]
    }
   ],
   "source": [
    "# assign labels to positive (1) and negative (0) reviews\n",
    "labels = np.zeros((data.shape[0], 1))\n",
    "labels[:d_pos.shape[0]] = 1\n",
    "\n",
    "target = np_utils.to_categorical(labels)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 8107)\n"
     ]
    }
   ],
   "source": [
    "ind = range(data.shape[0])\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7296, 34, 300) (811, 34, 300)\n",
      "(7296, 2) (811, 2)\n"
     ]
    }
   ],
   "source": [
    "#Split into train and test set\n",
    "ind = list(range(data.shape[0]))\n",
    "split = int(0.9 * data.shape[0])\n",
    "\n",
    "np.random.shuffle(ind)\n",
    "\n",
    "X_train = data[ind[:split]].reshape((-1, data.shape[1], data.shape[2]))#, 1))\n",
    "X_test = data[ind[split:]].reshape((-1, data.shape[1], data.shape[2]))#, 1))\n",
    "\n",
    "y_train = target[ind[:split]]\n",
    "y_test = target[ind[split:]]\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shivanikapania/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3144: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 1, 32)         67232     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 1, 16)         2576      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 1, 16)         784       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 352)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 352)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               45184     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 116,034\n",
      "Trainable params: 116,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Conv model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (7, 300), input_shape=(data.shape[1], 300, 1), activation='tanh'))\n",
    "model.add(Convolution2D(16, (5, 1), activation='tanh'))\n",
    "model.add(Convolution2D(16, (3, 1), activation='tanh'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 34, 128)           219648    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 34, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 351,490\n",
      "Trainable params: 351,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(data.shape[1], 300), return_sequences=True, activation='tanh'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128, activation='tanh'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder-decoder model\n",
    "# Example for seq2seq\n",
    "\n",
    "#model = Sequential()\n",
    "\n",
    "#model.add(LSTM(128, input_shape=(data.shape[1], 300), return_sequences=True, activation='tanh'))\n",
    "#model.add(LSTM(128, return_sequences=False))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shivanikapania/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7296 samples, validate on 811 samples\n",
      "Epoch 1/20\n",
      "7296/7296 [==============================] - 18s 2ms/step - loss: 0.5846 - acc: 0.6812 - val_loss: 0.5060 - val_acc: 0.7509\n",
      "Epoch 2/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.4723 - acc: 0.7710 - val_loss: 0.4908 - val_acc: 0.7534\n",
      "Epoch 3/20\n",
      "7296/7296 [==============================] - 16s 2ms/step - loss: 0.4463 - acc: 0.7882 - val_loss: 0.4789 - val_acc: 0.7546\n",
      "Epoch 4/20\n",
      "7296/7296 [==============================] - 16s 2ms/step - loss: 0.4175 - acc: 0.8080 - val_loss: 0.5111 - val_acc: 0.7435\n",
      "Epoch 5/20\n",
      "7296/7296 [==============================] - 16s 2ms/step - loss: 0.3902 - acc: 0.8187 - val_loss: 0.4722 - val_acc: 0.7608\n",
      "Epoch 6/20\n",
      "7296/7296 [==============================] - 16s 2ms/step - loss: 0.3547 - acc: 0.8396 - val_loss: 0.5384 - val_acc: 0.7645\n",
      "Epoch 7/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.3203 - acc: 0.8539 - val_loss: 0.5241 - val_acc: 0.7879\n",
      "Epoch 8/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.2704 - acc: 0.8846 - val_loss: 0.5830 - val_acc: 0.7793\n",
      "Epoch 9/20\n",
      "7296/7296 [==============================] - 16s 2ms/step - loss: 0.2234 - acc: 0.9060 - val_loss: 0.6177 - val_acc: 0.7793\n",
      "Epoch 10/20\n",
      "7296/7296 [==============================] - 16s 2ms/step - loss: 0.1795 - acc: 0.9279 - val_loss: 0.6553 - val_acc: 0.7731\n",
      "Epoch 11/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.1461 - acc: 0.9427 - val_loss: 0.7977 - val_acc: 0.7620\n",
      "Epoch 12/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.1241 - acc: 0.9526 - val_loss: 0.9013 - val_acc: 0.7731\n",
      "Epoch 13/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.0772 - acc: 0.9716 - val_loss: 0.9884 - val_acc: 0.7818\n",
      "Epoch 14/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.0577 - acc: 0.9801 - val_loss: 1.0647 - val_acc: 0.7571\n",
      "Epoch 15/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.0480 - acc: 0.9845 - val_loss: 1.1653 - val_acc: 0.7768\n",
      "Epoch 16/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.0419 - acc: 0.9851 - val_loss: 1.1460 - val_acc: 0.7830\n",
      "Epoch 17/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.0331 - acc: 0.9903 - val_loss: 1.2176 - val_acc: 0.7620\n",
      "Epoch 18/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.0354 - acc: 0.9877 - val_loss: 1.2429 - val_acc: 0.7707\n",
      "Epoch 19/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.0302 - acc: 0.9915 - val_loss: 1.1346 - val_acc: 0.7620\n",
      "Epoch 20/20\n",
      "7296/7296 [==============================] - 15s 2ms/step - loss: 0.0233 - acc: 0.9922 - val_loss: 1.2705 - val_acc: 0.7497\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "                epochs=20,\n",
    "                shuffle=True,\n",
    "                batch_size=100,\n",
    "                validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = spacy.load('en_vectors_web_lg')\n",
    "def sequence_to_mat(seq, lower_limit=10, upper_limit=35):\n",
    "    vec_seq = word_vec(str(seq))\n",
    "    if len(vec_seq) > lower_limit and len(vec_seq) < upper_limit:\n",
    "        m = np.ones((upper_limit-1, 300))*5.0\n",
    "        \n",
    "        for ix in range(len(vec_seq)):\n",
    "            m[ix, :] = vec_seq[ix].vector\n",
    "        return m\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 34, 300)\n"
     ]
    }
   ],
   "source": [
    "w = 'this has been an amazing movie definitely recommend it for watching'\n",
    "#w = 'this was not a decent experience, I had to sit there for a while'\n",
    "mat = sequence_to_mat(w)\n",
    "\n",
    "# example = np.expand_dims(np.expand_dims(mat, axis=0), axis=-1)\n",
    "example = np.expand_dims(mat, axis=0)\n",
    "print(example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01550869, 0.9844913 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
